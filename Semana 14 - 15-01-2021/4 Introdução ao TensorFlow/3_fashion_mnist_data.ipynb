{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LBUWKx1gEfM"
   },
   "source": [
    "# Coding a Computer Vision Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZh2TQ8fQB1P"
   },
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "grS-F9mCbCQn"
   },
   "outputs": [],
   "source": [
    "# importando o framework tensorflow (usando o keras)\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from matplotlib.pyplot import imshow\r\n",
    "# importando o pacote matemático numpy\r\n",
    "import numpy as np\r\n",
    "# importando o pacote de visualização de dados matplotlib\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "99VVZ2_1bMoC"
   },
   "outputs": [],
   "source": [
    "# carregando o dataset\r\n",
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uHW7UHqYbT6W"
   },
   "outputs": [],
   "source": [
    "# carregando os exemplos de treinamento e exemplos de teste do dataset\r\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Yiq6zyEaeIhC"
   },
   "outputs": [],
   "source": [
    "# definindo rótulos para todos os dados de saída númericos\r\n",
    "classes = {0: 'shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress',\r\n",
    "           4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker',\r\n",
    "           8: 'Bag', 9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "YB9hZLK9bf5c",
    "outputId": "5fffb0d9-29b8-471f-b91c-e75d42cb2e30"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'shirt/top'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizando com as imagens estão armazenadas\r\n",
    "index = 4\r\n",
    "imshow(train_images[index], cmap='gray')\r\n",
    "classes[train_labels[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUSF-7lLeyIw",
    "outputId": "4b488763-cc0c-4cb8-a8f8-d6535e9fd1bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 28, 28)\n",
      "train labels shape: (60000,)\n",
      "test shape: (10000, 28, 28)\n",
      "test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# visualizando as dimensões dos dados\r\n",
    "print('train shape: {}'.format(train_images.shape))\r\n",
    "print('train labels shape: {}'.format(train_labels.shape))\r\n",
    "print('test shape: {}'.format(test_images.shape))\r\n",
    "print('test labels shape: {}'.format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iN40cXIEfO_e"
   },
   "outputs": [],
   "source": [
    "# definindo um modelo da rede neural\r\n",
    "# == camada de entrada: transforma as entradas bidimensionais em uma camada achatada unidimensional ==\r\n",
    "# == primeira camada oculta: possui 128 neurônios (28 x 28) com uma função de ativação relu ==\r\n",
    "# == segunda camada oculta / camada de saída: possui 10 neurônios (correspondente a todos os rótulos) e com uma função de ativação softmax ==\r\n",
    "model = keras.Sequential([\r\n",
    "                          keras.layers.Flatten(input_shape = (28, 28)),\r\n",
    "                          keras.layers.Dense(128, activation = tf.nn.relu),\r\n",
    "                          keras.layers.Dense(10, activation = tf.nn.softmax)\r\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "id": "V3hdoyBDgzMo",
    "outputId": "ea764a2a-2143-43bb-b994-cf2eec6ab662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle boot\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# definindo configurações de impressão\r\n",
    "np.set_printoptions(linewidth=200)\r\n",
    "# visualizando a imagem bidimensional\r\n",
    "plt.imshow(train_images[0])\r\n",
    "# visualizando a classe a qual a imagem pertence\r\n",
    "print(classes[train_labels[0]])\r\n",
    "# visualizando o array bidimensional da imagem em questão\r\n",
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "s4HYhdzyJv8x"
   },
   "outputs": [],
   "source": [
    "# realizando a normalização nas imagens de treinamento e de teste \r\n",
    "train_images = train_images / 255\r\n",
    "test_images = test_images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6mpeqMzEJ-Sx"
   },
   "outputs": [],
   "source": [
    "# configurando os detalhes da compilação do modelo\r\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\r\n",
    "              loss = 'sparse_categorical_crossentropy',\r\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ZIY_On_Keqs",
    "outputId": "707cffad-ad28-4b45-f369-b8ecfa9a474c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.6268 - accuracy: 0.7802\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3758 - accuracy: 0.8651\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3370 - accuracy: 0.8772\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3060 - accuracy: 0.8878\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2912 - accuracy: 0.8915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f68c30c9908>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# realizando o treinamento do modelo\r\n",
    "model.fit(train_images, train_labels, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9HBtxXmKwma",
    "outputId": "5ea5aa40-d666-4e10-9d84-523b35871b4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35715362429618835, 0.8733000159263611]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usando os dados de teste para testar a capacidade de generalização do modelo\r\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjRfa-EkK_uA",
    "outputId": "8293d3e5-a869-4568-cd66-b2e3858f42a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.67376490e-05, 1.03073523e-06, 2.51393849e-05, 1.12673515e-05, 1.50829337e-05, 2.40795445e-02, 3.95375500e-05, 3.86070535e-02, 2.56261210e-05, 9.37168956e-01], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# realizando a predição em cada imagem de teste\r\n",
    "classifications = model.predict(test_images)\r\n",
    "# observe que a saída é a porcentagem de uma determinada imagem pertencer a uma determinada classe \r\n",
    "# (função de ativação na saída é do tipo softmax, para 10 neurônios dessa camada e 10 classes possíveis)\r\n",
    "classifications[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6QKO8-cMCWQ"
   },
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "v5faV6twLmnZ"
   },
   "outputs": [],
   "source": [
    "# baixando e carregando os dados de treinamento e dados de teste\r\n",
    "mnist = tf.keras.datasets.fashion_mnist\r\n",
    "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-_UrRivuMZRm"
   },
   "outputs": [],
   "source": [
    "# realizando a normalização nos dados\r\n",
    "training_images = training_images / 255\r\n",
    "testing_images = testing_images /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "I11fcZ_fMr2c"
   },
   "outputs": [],
   "source": [
    "# definindo o modelo da rede neural\r\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = (28, 28)),\r\n",
    "                                    tf.keras.layers.Dense(1024, activation = tf.nn.relu),\r\n",
    "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tNnd3UDUNKwA"
   },
   "outputs": [],
   "source": [
    "# configurando os detalhes da compilação do modelo\r\n",
    "model.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy',\r\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Ew3Gb6uNZph",
    "outputId": "51e07553-d5a4-43ed-9f57-c296873c064d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.5862 - accuracy: 0.7922\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3679 - accuracy: 0.8648\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3248 - accuracy: 0.8786\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3006 - accuracy: 0.8887\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2747 - accuracy: 0.8968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f68bbd23400>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# realizando o treinamento do modelo com os dados de treinamento\r\n",
    "model.fit(training_images, training_labels, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTczMVt_PXPX",
    "outputId": "033cdff4-f4a3-4ac5-f5df-8bb69515f1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3471 - accuracy: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3470785617828369, 0.8740000128746033]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usando os dados de teste para testar a capacidade de generalização do modelo\r\n",
    "model.evaluate(testing_images, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1CEw7_8QI0A",
    "outputId": "84f04b8b-eba5-4c07-c45b-58358739504f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.7959941e-07 2.5339471e-09 4.7845616e-09 7.1059721e-11 8.9538394e-09 4.2735557e-03 3.8169016e-08 1.1216225e-02 3.0706323e-07 9.8450941e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# verificando um exemplo de predição\r\n",
    "classifications = model.predict(testing_images)\r\n",
    "\r\n",
    "print(classifications[0])\r\n",
    "print(testing_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlTXn3m6QFrz"
   },
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD5yX1CuQhDq",
    "outputId": "1be33bee-7c01-4df5-d297-640e2b701efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5747 - accuracy: 0.7937\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.3617 - accuracy: 0.8659\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3247 - accuracy: 0.8805\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2917 - accuracy: 0.8908\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2818 - accuracy: 0.8930\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8788\n",
      "[7.0733743e-09 5.6782471e-11 8.3588171e-12 1.2483296e-09 6.4423161e-11 1.5808021e-03 2.3573193e-10 6.0502737e-04 2.8257054e-09 9.9781418e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\r\n",
    "\r\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\r\n",
    "\r\n",
    "training_images = training_images/255.0\r\n",
    "test_images = test_images/255.0\r\n",
    "\r\n",
    "# adicionando mais uma camada oculta (mudando a quantidade de neurônios da camada também)\r\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = (28, 28)),\r\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n",
    "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\r\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\r\n",
    "\r\n",
    "model.compile(optimizer = 'adam',\r\n",
    "              loss = 'sparse_categorical_crossentropy',\r\n",
    "              metrics = ['accuracy'])\r\n",
    "\r\n",
    "model.fit(training_images, training_labels, epochs=5)\r\n",
    "\r\n",
    "model.evaluate(test_images, test_labels)\r\n",
    "\r\n",
    "classifications = model.predict(test_images)\r\n",
    "\r\n",
    "print(classifications[0])\r\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1HdL2bV7RnJ9",
    "outputId": "b4a37032-5f2c-43fb-91be-99aab632831f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3463 - accuracy: 0.8788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3463383913040161, 0.8787999749183655]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usando os dados de teste para testar a capacidade de generalização do modelo\r\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvuXpgV8Rxf-"
   },
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1j405AAvRwa9",
    "outputId": "dbcf0822-3b2b-41fe-f080-106e901a488a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6367 - accuracy: 0.7820\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3795 - accuracy: 0.8633\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3380 - accuracy: 0.8763\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3068 - accuracy: 0.8892\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2960 - accuracy: 0.8906\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2837 - accuracy: 0.8940\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2625 - accuracy: 0.9025\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2523 - accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2431 - accuracy: 0.9107\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2400 - accuracy: 0.9101\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2323 - accuracy: 0.9140\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2241 - accuracy: 0.9181\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2116 - accuracy: 0.9208\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2018 - accuracy: 0.9257\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1989 - accuracy: 0.9239\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1939 - accuracy: 0.9276\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1887 - accuracy: 0.9289\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1856 - accuracy: 0.9309\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1779 - accuracy: 0.9322\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1756 - accuracy: 0.9319\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1668 - accuracy: 0.9367\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1644 - accuracy: 0.9375\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1625 - accuracy: 0.9378\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1583 - accuracy: 0.9406\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1550 - accuracy: 0.9424\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1525 - accuracy: 0.9433\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1454 - accuracy: 0.9461\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1440 - accuracy: 0.9457\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1444 - accuracy: 0.9458\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1413 - accuracy: 0.9466\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3826 - accuracy: 0.8908\n",
      "[3.15028800e-18 1.45600659e-24 7.94330867e-24 1.61239777e-30 7.76948415e-18 4.51395547e-26 1.99928248e-28 1.22370835e-29 1.00000000e+00 9.43685487e-35]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\r\n",
    "\r\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\r\n",
    "\r\n",
    "training_images = training_images/255.0\r\n",
    "test_images = test_images/255.0\r\n",
    "\r\n",
    "# voltando a definição da rede neural do modelo 1 (porém adicionando mais treinamento)\r\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = (28, 28)),\r\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\r\n",
    "\r\n",
    "model.compile(optimizer = 'adam',\r\n",
    "              loss = 'sparse_categorical_crossentropy',\r\n",
    "              metrics = ['accuracy'])\r\n",
    "\r\n",
    "# aumentando a quantidade de épocas para treinamento da rede neural\r\n",
    "model.fit(training_images, training_labels, epochs = 30)\r\n",
    "\r\n",
    "model.evaluate(test_images, test_labels)\r\n",
    "\r\n",
    "classifications = model.predict(test_images)\r\n",
    "\r\n",
    "print(classifications[34])\r\n",
    "print(test_labels[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF6awAeBSDre",
    "outputId": "18ae7b69-27af-4431-9d46-24fa0934df05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3826 - accuracy: 0.8908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3825541138648987, 0.8907999992370605]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# usando os dados de teste para testar a capacidade de generalização do modelo\r\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jE9Uo8sdVH0_"
   },
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jZesuBZ8W0lk"
   },
   "outputs": [],
   "source": [
    "# interrompendo um treinamento quando ele chega em um certo limiar\r\n",
    "class myCallback(tf.keras.callbacks.Callback):\r\n",
    "  def on_epoch_end(self, epoch, logs={}):\r\n",
    "    if(logs.get('loss')<0.4):\r\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\r\n",
    "      self.model.stop_training =True\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3K0P1WjVLP-",
    "outputId": "96ae985c-680f-4f8f-8b54-2e002b26dc9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5777 - accuracy: 0.7952\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3607 - accuracy: 0.8683\n",
      "\n",
      "Reached 60% accuracy so cancelling training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f68b68bc1d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = myCallback()\r\n",
    "mnist = tf.keras.datasets.fashion_mnist\r\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\r\n",
    "training_images=training_images/255.0\r\n",
    "test_images=test_images/255.0\r\n",
    "model = tf.keras.models.Sequential([\r\n",
    "  tf.keras.layers.Flatten(input_shape = (28, 28)),\r\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\r\n",
    "\r\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\r\n",
    "              metrics = ['accuracy'])\r\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlnumV0ca5qZ",
    "outputId": "69e40943-80c6-4542-d294-f8719c425ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4110 - accuracy: 0.8583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41095489263534546, 0.858299970626831]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "fashion mnist data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
